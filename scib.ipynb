{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911ae6e6-9eb8-4e6e-90d2-7265f726e06e",
   "metadata": {},
   "source": [
    "# NOTE:\n",
    "This is the same tutorial notebook from the main UCE repo. We have re run it with tabula sapiens v2 and the human brain cell atlas, which take a long time to run, for reproducibility and to demonstrate how to run the benchmark for large datasets by repeatedly resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b258384-9a56-4ed0-be6f-db1c94711356",
   "metadata": {},
   "source": [
    "# Large Scale Embedding benchmarks\n",
    "\n",
    "This notebook includes an example showing how to run large scale embedding benchmarks using scIB [(single-cell integration benchmark)](https://www.nature.com/articles/s41592-021-01336-8)\n",
    "\n",
    "We use the GPU accelerated version implemented here: https://github.com/YosefLab/scib-metrics\n",
    "\n",
    "Please follow installation instructions in that repo. \n",
    "\n",
    "*Note: installing Faiss can be difficult and may take some time*\n",
    "\n",
    "*Running the full benchmarking suite on many cells can take many hours, even on GPUs with large amounts of memory, such as A100s, and with many threads*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4ba3a1-5c85-4c7b-8564-f8c5689e9345",
   "metadata": {},
   "source": [
    "## Load Imports and define Benchmark Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d9fd58-915b-492d-9880-48c37e3859a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/ampere5/0/yanay/env/micromamba/envs/dogma/envs/faiss_1.8.0/lib/python3.11/site-packages/scanpy/_utils/__init__.py:35: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('anndata')` instead.\n",
      "  from anndata import __version__ as anndata_version\n",
      "/lfs/ampere5/0/yanay/env/micromamba/envs/dogma/envs/faiss_1.8.0/lib/python3.11/site-packages/anndata/__init__.py:70: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  return module_get_attr_redirect(attr_name, deprecated_mapping=_DEPRECATED)\n",
      "/lfs/ampere5/0/yanay/env/micromamba/envs/dogma/envs/faiss_1.8.0/lib/python3.11/site-packages/anndata/__init__.py:70: FutureWarning: Importing read_excel from `anndata` is deprecated. Import anndata.io.read_excel instead.\n",
      "  return module_get_attr_redirect(attr_name, deprecated_mapping=_DEPRECATED)\n",
      "/lfs/ampere5/0/yanay/env/micromamba/envs/dogma/envs/faiss_1.8.0/lib/python3.11/site-packages/anndata/__init__.py:70: FutureWarning: Importing read_hdf from `anndata` is deprecated. Import anndata.io.read_hdf instead.\n",
      "  return module_get_attr_redirect(attr_name, deprecated_mapping=_DEPRECATED)\n",
      "/lfs/ampere5/0/yanay/env/micromamba/envs/dogma/envs/faiss_1.8.0/lib/python3.11/site-packages/anndata/__init__.py:70: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  return module_get_attr_redirect(attr_name, deprecated_mapping=_DEPRECATED)\n",
      "/lfs/ampere5/0/yanay/env/micromamba/envs/dogma/envs/faiss_1.8.0/lib/python3.11/site-packages/anndata/__init__.py:70: FutureWarning: Importing read_mtx from `anndata` is deprecated. Import anndata.io.read_mtx instead.\n",
      "  return module_get_attr_redirect(attr_name, deprecated_mapping=_DEPRECATED)\n",
      "/lfs/ampere5/0/yanay/env/micromamba/envs/dogma/envs/faiss_1.8.0/lib/python3.11/site-packages/anndata/__init__.py:70: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  return module_get_attr_redirect(attr_name, deprecated_mapping=_DEPRECATED)\n",
      "/lfs/ampere5/0/yanay/env/micromamba/envs/dogma/envs/faiss_1.8.0/lib/python3.11/site-packages/anndata/__init__.py:70: FutureWarning: Importing read_umi_tools from `anndata` is deprecated. Import anndata.io.read_umi_tools instead.\n",
      "  return module_get_attr_redirect(attr_name, deprecated_mapping=_DEPRECATED)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "\n",
    "from scib_metrics.benchmark import Benchmarker\n",
    "\n",
    "import faiss\n",
    "\n",
    "from scib_metrics.nearest_neighbors import NeighborsResults\n",
    "\n",
    "# Faiss GPU accelerate nearest neighbors methods\n",
    "def faiss_hnsw_nn(X: np.ndarray, k: int):\n",
    "    \"\"\"Gpu HNSW nearest neighbor search using faiss.\n",
    "\n",
    "    See https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md\n",
    "    for index param details.\n",
    "    \"\"\"\n",
    "    X = np.ascontiguousarray(X, dtype=np.float32)\n",
    "    res = faiss.StandardGpuResources()\n",
    "    M = 32\n",
    "    index = faiss.IndexHNSWFlat(X.shape[1], M, faiss.METRIC_L2)\n",
    "    gpu_index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    gpu_index.add(X)\n",
    "    distances, indices = gpu_index.search(X, k)\n",
    "    del index\n",
    "    del gpu_index\n",
    "    # distances are squared\n",
    "    return NeighborsResults(indices=indices, distances=np.sqrt(distances))\n",
    "\n",
    "\n",
    "def faiss_brute_force_nn(X: np.ndarray, k: int):\n",
    "    \"\"\"Gpu brute force nearest neighbor search using faiss.\"\"\"\n",
    "    X = np.ascontiguousarray(X, dtype=np.float32)\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index = faiss.IndexFlatL2(X.shape[1])\n",
    "    gpu_index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    gpu_index.add(X)\n",
    "    distances, indices = gpu_index.search(X, k)\n",
    "    del index\n",
    "    del gpu_index\n",
    "    # distances are squared\n",
    "    return NeighborsResults(indices=indices, distances=np.sqrt(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c5fb90f-ffa5-4cb9-bf6a-6afce956fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scib_metrics.benchmark import Benchmarker, BioConservation, BatchCorrection\n",
    "import pandas as pd\n",
    "\n",
    "## Benchmarking Function, returns dataframe of scores\n",
    "def benchmark(ad, label_key=\"cell_type\", batch_key=\"sample_id\", obsm_keys=[\"X_uce\", \"X_scGPT\", \"X_geneformer\"]):\n",
    "    print(f\"Running using CT key:\", label_key)\n",
    "    biocons = BioConservation()\n",
    "    batchcons = BatchCorrection(pcr_comparison=False)\n",
    "    \n",
    "    bm = Benchmarker(\n",
    "        ad,\n",
    "        batch_key=batch_key,\n",
    "        label_key=label_key,\n",
    "        embedding_obsm_keys=obsm_keys,\n",
    "        bio_conservation_metrics=biocons,\n",
    "        batch_correction_metrics=None,\n",
    "        n_jobs=48,\n",
    "    )\n",
    "    bm.prepare(neighbor_computer=faiss_brute_force_nn)\n",
    "    bm.benchmark()\n",
    "    df = bm.get_results(min_max_scale=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bb257-21d4-41d5-9726-50b5e7af04b2",
   "metadata": {},
   "source": [
    "### Load in anndata\n",
    "\n",
    "For this example, we will benchmark cells from developing mouse brain.\n",
    "\n",
    "You can download an anndata object with UCE, scGPT and Geneformer embeddings precalulated from [here](https://drive.google.com/drive/folders/1f63fh0ykgEhCrkd_EVvIootBw7LYDVI7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed9ee327-7587-4b5c-83aa-9c3ddbc4fbdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 581430 × 45792\n",
       "    obs: 'donor', 'tissue', 'anatomical_position', 'method', 'cdna_plate', 'library_plate', 'notes', 'cdna_well', 'old_index', 'assay', 'sample_id', 'sample', 'replicate', '10X_run', '10X_barcode', 'ambient_removal', 'donor_method', 'donor_assay', 'donor_tissue', 'donor_tissue_assay', 'cell_ontology_class', 'cell_ontology_id', 'compartment', 'broad_cell_class', 'free_annotation', 'manually_annotated', 'published_2022', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ercc', 'pct_counts_ercc', '_scvi_batch', '_scvi_labels', 'scvi_leiden_donorassay_full', 'age', 'sex', 'ethnicity', 'n_genes', 'donor_num', 'cell_type_coarse', 'n_counts'\n",
       "    var: 'n_cells'\n",
       "    uns: 'log1p', 'neighbors', 'pca', 'umap'\n",
       "    obsm: 'X_geneformer', 'X_pca', 'X_scarches_seed0', 'X_scgpt', 'X_scvi_seed0', 'X_tgpt', 'X_uce'\n",
       "    varm: 'PCs'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabula_ad = sc.read(\"export_data/new_tabula_all_zero_shot_lognorm.h5ad\")\n",
    "tabula_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4cb1a5e-1672-4ba7-b488-036de0e3ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_column = \"cell_ontology_class\"\n",
    "batch_column = \"sample_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "134f4e09-8e68-43fb-9d12-d87a1b5318c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tabula_ad.obs[cell_type_column].unique()) # Number of unique cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac956e69-9a66-4225-adb8-a01a2d6e23bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tabula_ad.obs[batch_column].unique()) # Number of unique batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c790b976-1e84-40e2-ac07-8c12239e029c",
   "metadata": {},
   "source": [
    "# Running the Benchmark on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2afc3328-d644-443d-8a60-73afc39b5575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.8547866e-02, -2.5216730e-02,  9.2354268e-03, ...,\n",
       "        -8.5126543e-03,  6.3443370e-03, -5.0794845e-03],\n",
       "       [ 1.2552227e-02,  1.3078367e-02, -8.7940758e-03, ...,\n",
       "        -2.1045651e-02, -5.7123909e-03,  1.3679673e-02],\n",
       "       [ 4.4793326e-02, -1.8928792e-02,  1.3293503e-02, ...,\n",
       "        -9.8256329e-03,  7.7304617e-03, -3.6268145e-02],\n",
       "       ...,\n",
       "       [ 1.3699106e-02, -2.5936974e-02, -2.7112808e-05, ...,\n",
       "         2.1766354e-03, -3.2877855e-02, -6.6242784e-02],\n",
       "       [-9.9301739e-03, -1.1609541e-02, -9.7841416e-03, ...,\n",
       "        -1.6720660e-02,  5.5857226e-03, -1.1244461e-02],\n",
       "       [ 4.5787334e-04, -2.6317516e-02, -1.3252082e-02, ...,\n",
       "        -1.6145144e-02,  1.5398547e-02, -2.4077728e-02]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabula_ad.obsm[\"X_uce\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290c14b9-cab9-4126-bc8c-a56169189a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_ad = sc.pp.subsample(tabula_ad, n_obs=560_000, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f63bba-8ae3-461e-bb32-6dcf95a6b7dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_tabula_benchmark_results_df = benchmark(subsample_ad, label_key=cell_type_column,  batch_key=batch_column, obsm_keys=['X_uce', 'X_geneformer',  'X_scgpt','X_tgpt', 'X_pca', 'X_scvi_seed0', 'X_scarches_seed0'])\n",
    "new_tabula_benchmark_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf6f17-bbf7-4662-9e18-c196b8aa1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'X_pca', 'X_scvi_seed0', 'X_scarches_seed0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e59842-2e11-47b8-864c-c556f8c8a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee280476-4057-4051-b4f1-eb7ee0055e69",
   "metadata": {},
   "source": [
    "# Running the Benchmark using Resampling (Human Brain Cell Atlas)\n",
    "\n",
    "Running the benchmark on the full dataset can take a very long time. Instead, we can run on medium sized samples of cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae96b8-5be1-4ea5-a919-d16d2205d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100_000 # number of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ad01d-83c0-40e6-ab13-d16ed7eb0c88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "sample_score_dfs = []\n",
    "\n",
    "for i in tqdm(range(N_RESAMPLES)):\n",
    "    # benchmark one sample\n",
    "    # sample is drawn with random state i\n",
    "    subsample_ad = sc.pp.subsample(ad, copy=True, n_obs=sample_size, random_state=i)\n",
    "    sample_df = benchmark(subsample_ad, label_key=cell_type_column,  batch_key=batch_column)\n",
    "    # show the results for this sample\n",
    "    display(subsample_ad)\n",
    "    # add it to the results for all samples\n",
    "    sample_score_dfs.append(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131fee3d-108d-4685-8afb-ec2863775b2f",
   "metadata": {},
   "source": [
    "# Final Scores\n",
    "\n",
    "We can aggregate the scores from all the samples, taking the mean value (and standard deviation of the score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd62bbd-f8ac-453f-b172-76cff96e5fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_mean = pd.concat([df.drop(\"Metric Type\").reset_index() for df in sample_score_dfs]).groupby(\"Embedding\").agg(np.mean)\n",
    "# Note: we drop the \"Metric Type\" row since it contains strings which we can't take the mean of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0216e0-7d47-4c8c-a094-c27642b8669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_std = pd.concat([df.drop(\"Metric Type\").reset_index() for df in sample_score_dfs]).groupby(\"Embedding\").agg(np.std)\n",
    "# Note: we drop the \"Metric Type\" row since it contains strings which we can't take the std of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db86f16-ad9b-486d-935b-c69084866f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71d4f4-1555-4cea-8f8f-332075e00de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_mean[\"Bio conservation\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Faiss",
   "language": "python",
   "name": "faiss_1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
