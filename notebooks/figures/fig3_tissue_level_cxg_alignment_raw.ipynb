{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from geosketch import gs\n",
    "from fbpca import pca\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from uce_utils import read_uce_embed\n",
    "#from cell_type_map_gpt import cell_type_mapping\n",
    "\n",
    "import sys\n",
    "sys.path.append('/dfs/user/yhr/cross-species-coarse/')\n",
    "import matplotlib.pyplot as plt\n",
    "from cs_utils import plotly_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = np.load('all_datasets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = [\"/lfs/local/0/yanay/cxg_npzs/\" + f\"{x}_counts.npz\" for x in np.unique(all_datasets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxg_shared_genes = np.load('../cxg_shared_genes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Non-h5ad route\n",
    "\n",
    "#all_paths = glob.glob('/lfs/local/0/yanay/uce_all_proc_4layer/*')\n",
    "\n",
    "## Only relevant datasets\n",
    "all_paths = [\"/lfs/local/0/yanay/cxg_npzs/\" + f\"{x}_counts.npz\" for x in set(all_datasets)]\n",
    "\n",
    "all_gene_names = []\n",
    "success_loads = []\n",
    "cxg_shared_genes = np.load('cxg_shared_genes.npy')\n",
    "\n",
    "# Get the total number of rows in the final matrix\n",
    "total_rows = sum(int(path.split('cells_')[-1].split('_')[0]) for path in all_paths)\n",
    "\n",
    "# Create a memory-mapped array to store the final matrix\n",
    "giant_matrix = np.memmap('/lfs/local/0/yhr/uce_all_proc/big_matrix_4layer_', shape=(total_rows, 1280), dtype='float32', mode='w+')\n",
    "\n",
    "# Write data from each file to the memory-mapped array \n",
    "current_row = 0\n",
    "for path in tqdm(all_paths, desc='Progress', unit='file'):\n",
    "    try:\n",
    "        ncells = int(path.split('cells_')[-1].split('_')[0])\n",
    "        arr = np.memmap(path, shape=(ncells, 1280), dtype=\"float32\", mode='r')\n",
    "        giant_matrix[current_row:current_row + ncells, :] = arr\n",
    "        current_row += ncells\n",
    "    except:\n",
    "        print('ERROR', path)\n",
    "\n",
    "## Flush the memory-mapped array to ensure data is written to disk\n",
    "giant_matrix.flush()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Load Cell Types\n",
    "ct_path = f\"/lfs/local/0/yanay/all_cell_types/{name}.pkl\"\n",
    "with open(ct_path, \"rb\") as f:\n",
    "    cell_types = pkl.load(f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  21%|████████████████████████████▊                                                                                                           | 39/184 [06:01<07:53,  3.27s/file]"
     ]
    }
   ],
   "source": [
    "#all_paths = glob.glob('/lfs/local/0/yanay/uce_all_proc_4layer/*')\n",
    "\n",
    "## Only relevant datasets\n",
    "all_paths = ['/lfs/local/0/yanay/cxg_h5s/'+x+'_proc.h5ad' for x in np.unique(all_datasets)]\n",
    "\n",
    "all_h5ads = []\n",
    "all_gene_names = []\n",
    "success_loads = []\n",
    "all_cell_types = []\n",
    "cxg_shared_genes = np.load('cxg_shared_genes.npy')\n",
    "\n",
    "failed_loads = []\n",
    "for path in tqdm(all_paths, desc='Progress', unit='file'):\n",
    "    \n",
    "    #dataset_name = path.split('_')[-1].split('_counts')[0].split('.npz')[0]\n",
    "    #raw_dataset_name = '/lfs/local/0/yanay/cxg_h5s/' + dataset_name +'_proc.h5ad'\n",
    "    raw_dataset_name = path\n",
    "    \n",
    "    try:\n",
    "        #ncells = int(path.split('cells_')[-1].split('_')[0])\n",
    "        read_adata = sc.read_h5ad(raw_dataset_name)\n",
    "        read_adata = read_adata[:, cxg_shared_genes]\n",
    "        \n",
    "        if read_adata.shape[1]<100:\n",
    "            failed_loads.append(dataset_name)\n",
    "            continue\n",
    "\n",
    "        gene_names = read_adata.var.index.values\n",
    "        all_gene_names.append(gene_names)\n",
    "        success_loads.append(raw_dataset_name)\n",
    "        \n",
    "        all_h5ads.append(sp.csr_matrix(read_adata.X))\n",
    "        all_cell_types.extend(read_adata.obs['cell_type'].values)\n",
    "        #all_h5ads.append()\n",
    "        #arr = np.memmap(path, shape=(ncells, 1280), dtype=\"float32\", mode='r')\n",
    "        #giant_matrix[current_row:current_row + ncells, :] = arr\n",
    "        #current_row += ncells\n",
    "    except:\n",
    "        failed_loads.append(dataset_name)\n",
    "        print('ERROR', dataset_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all intermediate data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrices = sp.vstack(all_h5ads)\n",
    "sp.save_npz('fig4_raw_counts.npz', data_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_datasets_list = []\n",
    "for h5ad, dataset_ in zip(all_h5ads, np.unique(all_datasets)):\n",
    "    all_datasets_list.extend([dataset_]*h5ad.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = pd.DataFrame()\n",
    "var_df.index = all_gene_names[0]\n",
    "data_matrices_h5ad.var = var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrices_h5ad.obs['cell_type'] = all_cell_types\n",
    "data_matrices_h5ad.obs['dataset'] = all_datasets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('fig4_cell_types.npy', all_cell_types)\n",
    "np.save('fig4_datasets.npy', all_datasets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19284565, 5704)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrices_h5ad.write_h5ad('fig4_raw_counts.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = []\n",
    "\n",
    "for itr, x in enumerate(success_loads):\n",
    "    all_datasets.extend([x]*all_lengths[itr])\n",
    "    \n",
    "np.save('all_datasets.npy', all_datasets)\n",
    "\n",
    "all_lengths = [len(x) for x in all_h5ads]\n",
    "all_lengths = np.hstack(all_lengths)\n",
    "np.save('all_lengths.npy', all_cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_types = [x.obs['cell_type'].values for x in all_h5ads]\n",
    "all_cell_types = np.hstack(all_cell_types)\n",
    "\n",
    "np.save('all_cell_types.npy', all_cell_types)\n",
    "np.save('success_loads.npy', success_loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6\n",
      "16\n",
      "17\n",
      "20\n",
      "37\n",
      "58\n",
      "90\n",
      "94\n",
      "103\n",
      "113\n",
      "114\n",
      "121\n",
      "132\n",
      "160\n",
      "162\n",
      "167\n",
      "211\n",
      "218\n",
      "270\n",
      "275\n"
     ]
    }
   ],
   "source": [
    "shared_set = set(all_gene_names[0])\n",
    "test = set(all_gene_names[0])\n",
    "\n",
    "for itr, x in enumerate(all_gene_names):\n",
    "    test = shared_set.intersection(set(x))\n",
    "    if len(test)>100:\n",
    "        shared_set = shared_set.intersection(set(x))\n",
    "        test = set(shared_set)\n",
    "    else:\n",
    "        print(itr)\n",
    "        \n",
    "np.save('cxg_shared_genes.npy', list(shared_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in tabula sapiens dataset - new donors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use updated gene list based on Tabula Sapiens\n",
    "all_gene_names_edit = [item for item in all_gene_names if item != 'PHB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrices_h5ad.X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrices_h5ad = sc.read_h5ad('fig4_raw_counts.h5ad')\n",
    "data_matrices_h5ad = data_matrices_h5ad[:, all_gene_names_edit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabula_sapiens = sc.read_h5ad('/lfs/local/0/yanay/uce_temp/new_tabula_sapiens_ep_4_sn_125827_nlayers_4_sample_size_1024.h5ad')\n",
    "tabula_sapiens = tabula_sapiens[:, all_gene_names_edit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/user/20138/ipykernel_3413270/561214536.py:1: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  tabula_sapiens.obs['dataset']='TS'\n"
     ]
    }
   ],
   "source": [
    "tabula_sapiens.obs['dataset']='TS'\n",
    "tabula_sapiens = tabula_sapiens[tabula_sapiens.obs['donor'].isin([f'TSP{x}' for x in np.arange(16,31)])]\n",
    "tabula_sapiens.obs['cell_type'] = tabula_sapiens.obs['cell_ontology_class'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_concat = sc.concat([data_matrices_h5ad, tabula_sapiens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 19865995 × 5703\n",
       "    obs: 'cell_type', 'dataset'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data and compute centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata_concat)\n",
    "sc.pp.log1p(adata_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now after normalization separate out CxG centroids from TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxg_adata = adata_concat[adata_concat.obs['dataset']!='TS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 19284565 × 5703\n",
       "    obs: 'cell_type', 'dataset'\n",
       "    uns: 'log1p'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cxg_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_types = cxg_adata.obs['cell_type'].values\n",
    "all_cell_types_uq = cxg_adata.obs['cell_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSP30_Ovary_NA_SS3_Blue_B105390_LiveDead_D9       smooth muscle cell\n",
       "TSP30_Ovary_NA_SS3_Blue_B105394_LiveDead_E22        endothelial cell\n",
       "TSP30_Ovary_NA_SS3_Blue_B105394_LiveDead_P4       smooth muscle cell\n",
       "TSP30_Ovary_NA_SS3_B004411_B105393_LiveDead_I1    smooth muscle cell\n",
       "TSP30_Ovary_NA_SS3_Blue_B105394_LiveDead_O4       smooth muscle cell\n",
       "                                                         ...        \n",
       "TSP25_FAT_Brown_10X_1_6_TTTGTTGCAAAGCACG                      b cell\n",
       "TSP25_FAT_Brown_10X_1_6_TTTGTTGGTAAGTCAA                      b cell\n",
       "TSP25_FAT_Brown_10X_1_6_TTTGTTGGTATACCCA                  fibroblast\n",
       "TSP25_FAT_Brown_10X_1_6_TTTGTTGGTGTGTCCG                      b cell\n",
       "TSP25_FAT_Brown_10X_1_6_TTTGTTGTCAAGCGTT          smooth muscle cell\n",
       "Name: cell_type, Length: 581430, dtype: category\n",
       "Categories (162, object): ['acinar cell', 'acinar cell of salivary gland', 'activated cd4-positive, alpha-beta t cell', 'activated cd8-positive, alpha-beta t cell', ..., 'vascular associated smooth muscle cell', 'vein endothelial cell', 'ventricular cardiac muscle cell', 'vestibular dark cell']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabula_sapiens.obs['cell_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSP30_Ovary_NA_SS3_Blue_B105390_LiveDead_D9       Ovary\n",
       "TSP30_Ovary_NA_SS3_Blue_B105394_LiveDead_E22      Ovary\n",
       "TSP30_Ovary_NA_SS3_Blue_B105394_LiveDead_P4       Ovary\n",
       "TSP30_Ovary_NA_SS3_B004411_B105393_LiveDead_I1    Ovary\n",
       "TSP30_Ovary_NA_SS3_Blue_B105394_LiveDead_O4       Ovary\n",
       "                                                  ...  \n",
       "TSP25_FAT_Brown_10X_1_6_TTTGTTGCAAAGCACG            Fat\n",
       "TSP25_FAT_Brown_10X_1_6_TTTGTTGGTAAGTCAA            Fat\n",
       "TSP25_FAT_Brown_10X_1_6_TTTGTTGGTATACCCA            Fat\n",
       "TSP25_FAT_Brown_10X_1_6_TTTGTTGGTGTGTCCG            Fat\n",
       "TSP25_FAT_Brown_10X_1_6_TTTGTTGTCAAGCGTT            Fat\n",
       "Name: tissue, Length: 581430, dtype: category\n",
       "Categories (27, object): ['Bladder', 'Blood', 'Bone_Marrow', 'Ear', ..., 'Tongue', 'Trachea', 'Uterus', 'Vasculature']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 476/476 [05:44<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "centroids = {}\n",
    "for c in tqdm(all_cell_types_uq, total=len(all_cell_types_uq)):\n",
    "    idxs = np.where(all_cell_types==c)\n",
    "    subset_matrix = cxg_adata[idxs].X.toarray()\n",
    "    centroids[c] = np.mean(subset_matrix,0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_centroids = pd.DataFrame.from_dict(centroids)\n",
    "all_centroids = all_centroids.T\n",
    "all_centroids.columns = cxg_adata.var.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_centroids.to_csv('fig4_centroids_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compute centroids for TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabula_adata = adata_concat[adata_concat.obs['dataset']=='TS']\n",
    "tabula_adata.obs['tissue'] = tabula_sapiens.obs['tissue'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, compute alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue = 'Bladder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_results(concat_centroids, num_nbrs=[2], max_possible=None):\n",
    "    \n",
    "    results_dict = {}\n",
    "    for n_neighbors in num_nbrs:\n",
    "\n",
    "        # Create a NearestNeighbors model\n",
    "        nn_model = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "\n",
    "        # Fit the model to your data\n",
    "        nn_model.fit(concat_centroids)\n",
    "\n",
    "        # Find the 1 nearest neighbor for each row\n",
    "        distances, indices = nn_model.kneighbors(concat_centroids)\n",
    "\n",
    "        # Create a new DataFrame to store the nearest neighbors and distances\n",
    "        nearest_neighbors_dict = {concat_centroids.index[i]: np.array(concat_centroids.index)[indices[i, 1:n_neighbors]] \n",
    "                              for i in range(len(concat_centroids))\n",
    "                              if '_TS' in concat_centroids.index[i]}\n",
    "\n",
    "        matches = []\n",
    "        not_matched = []\n",
    "\n",
    "        for cell, neighbors in nearest_neighbors_dict.items():\n",
    "            not_matched_flag = 1\n",
    "            for n in neighbors:\n",
    "                if cell.strip('_TS').lower() == n.lower():\n",
    "                    not_matched_flag = 0\n",
    "                    matches.append(cell)\n",
    "                    break\n",
    "            if not_matched_flag == 1:\n",
    "                not_matched.append(cell)  \n",
    "\n",
    "        not_matched = list(set(not_matched))\n",
    "        if max_possible is not None:\n",
    "            results_dict[n_neighbors] = len(matches)/max_possible\n",
    "        else:\n",
    "            results_dict[n_neighbors] = len(matches)\n",
    "    \n",
    "    return results_dict, not_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ovary\n",
      "Stomach\n",
      "Fat\n",
      "Thymus\n",
      "Blood\n",
      "Bladder\n",
      "Small_Intestine\n",
      "Salivary_Gland\n",
      "Skin\n",
      "Muscle\n",
      "Bone_Marrow\n",
      "Lung\n",
      "Testis\n",
      "Lymph_Node\n",
      "Vasculature\n",
      "Ear\n",
      "Spleen\n",
      "Large_Intestine\n",
      "Trachea\n",
      "Prostate\n",
      "Uterus\n",
      "Pancreas\n",
      "Eye\n",
      "Liver\n",
      "Mammary\n",
      "Heart\n",
      "Tongue\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "num_nbrs = 4\n",
    "\n",
    "for tissue in tabula_adata.obs['tissue'].unique():\n",
    "    print(tissue)\n",
    "    \n",
    "    tabula_tissue = tabula_adata[tabula_adata.obs['tissue']==tissue]\n",
    "    tabula_tissue_df = tabula_tissue.to_df()\n",
    "    tabula_tissue_df['cell_type'] = tabula_tissue.obs['cell_type']\n",
    "    tabula_tissue_centroids = tabula_tissue_df.groupby('cell_type').mean()\n",
    "    tabula_tissue_centroids.index = [x+'_TS' for x in tabula_tissue_centroids.index.values]\n",
    "\n",
    "    all_centroids.columns = all_centroids.columns.astype('str')\n",
    "    tabula_tissue_centroids.columns = tabula_tissue_centroids.columns.astype('str')\n",
    "\n",
    "    # Concatenate with IMA centroids\n",
    "    concat_centroids = pd.concat([all_centroids, tabula_tissue_centroids])\n",
    "    max_possible = len(set(tabula_tissue_df['cell_type'].unique().tolist()).intersection(\n",
    "                        set(all_centroids.index.values)))\n",
    "    \n",
    "    results_dict, _ = get_nn_results(concat_centroids, \n",
    "                                     num_nbrs=[num_nbrs], \n",
    "                                     max_possible=max_possible)\n",
    "    all_results[tissue] = results_dict\n",
    "\n",
    "np.save(f'nn_{num_nbrs}_raw', all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ovary': {2: 0.1},\n",
       " 'Stomach': {2: 0.2727272727272727},\n",
       " 'Fat': {2: 0.1111111111111111},\n",
       " 'Thymus': {2: 0.11764705882352941},\n",
       " 'Blood': {2: 0.07692307692307693},\n",
       " 'Bladder': {2: 0.2},\n",
       " 'Small_Intestine': {2: 0.16666666666666666},\n",
       " 'Salivary_Gland': {2: 0.17647058823529413},\n",
       " 'Skin': {2: 0.2222222222222222},\n",
       " 'Muscle': {2: 0.047619047619047616},\n",
       " 'Bone_Marrow': {2: 0.10526315789473684},\n",
       " 'Lung': {2: 0.13043478260869565},\n",
       " 'Testis': {2: 0.2},\n",
       " 'Lymph_Node': {2: 0.07142857142857142},\n",
       " 'Vasculature': {2: 0.09090909090909091},\n",
       " 'Ear': {2: 0.16666666666666666},\n",
       " 'Spleen': {2: 0.058823529411764705},\n",
       " 'Large_Intestine': {2: 0.0},\n",
       " 'Trachea': {2: 0.1875},\n",
       " 'Prostate': {2: 0.3333333333333333},\n",
       " 'Uterus': {2: 0.18181818181818182},\n",
       " 'Pancreas': {2: 0.0},\n",
       " 'Eye': {2: 0.17391304347826086},\n",
       " 'Liver': {2: 0.1875},\n",
       " 'Mammary': {2: 0.0},\n",
       " 'Heart': {2: 0.0625},\n",
       " 'Tongue': {2: 0.18181818181818182}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepamp",
   "language": "python",
   "name": "deepamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
